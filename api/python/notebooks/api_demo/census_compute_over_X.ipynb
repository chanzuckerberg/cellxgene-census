{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing on X: using online algorithms\n",
    "\n",
    "*Goal:* demonstrate larger-than-core computation on the X matrix, using \"online\" algorithms to process data incrementally.\n",
    "\n",
    "This notebook computes a variety of per-gene and per-cell statistics for a user-defined query.\n",
    "\n",
    "*NOTE*: when query results are small, it may be easier to use the SOMAExperment Query class to extract an AnnData, and then just compute over that. This notebook is showing means of incrementally processing larger-than-core (RAM) data, where incremental (online) algorithms are used.\n",
    "\n",
    "\n",
    "First, open up part of the census."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cell_census\n",
    "import tiledbsoma as soma\n",
    "import somacore\n",
    "\n",
    "census = cell_census.open_soma()\n",
    "mouse = census[\"census_data\"][\"mus_musculus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple incremental (aka \"online\") calculations\n",
    "\n",
    "Many statistics, such as `mean`, are easy to calculate incrementally.  This cell demonstrates a query on the `X['raw']` sparse nD array, which will return results in batches. Accumulate the sum and count incrementally, into `raw_sum` and `raw_n`, and then compute mean.\n",
    "\n",
    "First define a query - in this case a slice over the obs axis for cells with a specific tissue & sex value, and all genes on the var axis.  The `query.X()` method returns an iterator of results, each as a PyArrow Table.  Each table will contain the sparse X data and obs/var coordinates, using standard SOMA names:\n",
    "* `soma_data` - the X value (float32)\n",
    "* `soma_dim_0` - the obs coordinate (int64)\n",
    "* `soma_dim_1` - the var coordinate (int64)\n",
    "\n",
    "**Important**: the X matrices are joined to var/obs axis DataFrames by an integer join \"id\" (aka `soma_joinid`). They are *NOT* positionally indexed, and any given cell or gene may have a `soma_joinid` of any value (e.g., a large integer). In other words, for any given `X` value, the `soma_dim_0` corresponds to the `soma_joinid` in the `obs` dataframe, and the `soma_dim_` coordinate corresponds to the `soma_joinid` in the `var` dataframe.\n",
    "\n",
    "For convenience, the query package contains a utility function to simplify operations on query slices.  `query._indexer` returns an indexer that can be used to wrap the output of `query.X()`, converting from `soma_joinids` to positional indexing. Positions are `[0, N)`, where `N` are the number of results on the query for any given axis (equivalent to the Pandas `.iloc` of the axis dataframe).\n",
    "\n",
    "Key points:\n",
    "* it is expensive to query and read the results - so rather than make multiple passes over the data, read it once and perform multiple computations.\n",
    "* by default, data in the census is indexed by `soma_joinid` and not positionally. Use `query._indexer` if you want positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mouse.axis_query(\n",
    "    measurement_name=\"RNA\",\n",
    "    obs_query=somacore.AxisQuery(value_filter=\"tissue=='brain' and sex=='male'\"),\n",
    ") as query:\n",
    "    var_df = query.var().concat().to_pandas().set_index(\"soma_joinid\")\n",
    "    n_vars = len(var_df)\n",
    "\n",
    "    raw_n = np.zeros((n_vars,), dtype=np.int64)  # accumulate number of non-zero X values\n",
    "    raw_sum = np.zeros((n_vars,), dtype=np.float64)  # accumulate the sum of expression\n",
    "\n",
    "    # query.X() returns an iterator of pyarrow.Table, with X data in COO format.\n",
    "    # You can request an indexer from the query that will map it to positional indices\n",
    "    indexer = query._indexer\n",
    "    for arrow_tbl in query.X(\"raw\").tables():\n",
    "        var_dim = indexer.by_var(arrow_tbl[\"soma_dim_1\"])\n",
    "        data = arrow_tbl[\"soma_data\"]\n",
    "        np.add.at(raw_n, var_dim, 1)\n",
    "        np.add.at(raw_sum, var_dim, data)\n",
    "\n",
    "with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "    raw_mean = raw_sum / query.n_obs\n",
    "raw_mean[np.isnan(raw_mean)] = 0\n",
    "\n",
    "var_df = var_df.assign(raw_n=pd.Series(data=raw_n, index=var_df.index))\n",
    "var_df = var_df.assign(raw_mean=pd.Series(data=raw_mean, index=var_df.index))\n",
    "\n",
    "display(var_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex online calculations\n",
    "\n",
    "Other statistics are not as simple when implemented as an online algorithm. This cell demonstrates an implementation of an online computation of `variance`, using [Welford's online calculation of mean and variance](https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_online_algorithm).\n",
    "\n",
    "This code is also available in the `cell_census.compute` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tiledbsoma' has no attribute 'experiment_query'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 77\u001b[0m\n\u001b[1;32m     71\u001b[0m     M2 \u001b[38;5;241m=\u001b[39m M2_a \u001b[38;5;241m+\u001b[39m delta\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m n_a \u001b[38;5;241m*\u001b[39m n_b \u001b[38;5;241m/\u001b[39m n_samples  \u001b[38;5;66;03m# assumes M2_b == 0\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m u, M2\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mouse\u001b[38;5;241m.\u001b[39maxis_query(\n\u001b[1;32m     76\u001b[0m     measurement_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRNA\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m---> 77\u001b[0m     obs_query\u001b[38;5;241m=\u001b[39m\u001b[43msoma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment_query\u001b[49m\u001b[38;5;241m.\u001b[39mAxisQuery(value_filter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtissue==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrain\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and sex==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmale\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     78\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m query:\n\u001b[1;32m     79\u001b[0m     var_df \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mvar()\u001b[38;5;241m.\u001b[39mconcat()\u001b[38;5;241m.\u001b[39mto_pandas()\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoma_joinid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     80\u001b[0m     n_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(var_df)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tiledbsoma' has no attribute 'experiment_query'"
     ]
    }
   ],
   "source": [
    "import numba\n",
    "import numpy.typing as npt\n",
    "\n",
    "\n",
    "class OnlineMatrixMeanVariance:\n",
    "    n_samples: int\n",
    "    n_variables: int\n",
    "\n",
    "    def __init__(self, n_samples: int, n_variables: int):\n",
    "        \"\"\"\n",
    "        Compute mean and variance for n_variables over n_samples, encoded\n",
    "        in a COO format. Equivalent to:\n",
    "            numpy.mean(data, axis=0)\n",
    "            numpy.var(data, axix=0)\n",
    "        where the input `data` is of shape (n_samples, n_variables)\n",
    "        \"\"\"\n",
    "        self.n_samples = n_samples\n",
    "        self.n_variables = n_variables\n",
    "\n",
    "        self.n_a = np.zeros((n_variables,), dtype=np.int32)\n",
    "        self.u_a = np.zeros((n_variables,), dtype=np.float64)\n",
    "        self.M2_a = np.zeros((n_variables,), dtype=np.float64)\n",
    "\n",
    "    def update(self, coord_vec: npt.NDArray[np.int64], value_vec: npt.NDArray[np.float32]) -> None:\n",
    "        _mean_variance_update(coord_vec, value_vec, self.n_a, self.u_a, self.M2_a)\n",
    "\n",
    "    def finalize(self) -> tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]]:\n",
    "        \"\"\"\n",
    "        Returns tuple containing mean and variance\n",
    "        \"\"\"\n",
    "        u, M2 = _mean_variance_finalize(self.n_samples, self.n_a, self.u_a, self.M2_a)\n",
    "\n",
    "        # compute sample variance\n",
    "        var = M2 / max(1, (self.n_samples - 1))\n",
    "\n",
    "        return u, var\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def _mean_variance_update(\n",
    "    col_arr: npt.NDArray[np.int64],\n",
    "    val_arr: npt.NDArray[np.float32],\n",
    "    n: npt.NDArray[np.int32],\n",
    "    u: npt.NDArray[np.float64],\n",
    "    M2: npt.NDArray[np.float64],\n",
    "):\n",
    "    \"\"\"\n",
    "    Incrementally accumulate mean and sum of square of distance from mean using\n",
    "    Welford's online method.\n",
    "    \"\"\"\n",
    "    for col, val in zip(col_arr, val_arr):\n",
    "        u_prev = u[col]\n",
    "        M2_prev = M2[col]\n",
    "        n[col] += 1\n",
    "        u[col] = u_prev + (val - u_prev) / n[col]\n",
    "        M2[col] = M2_prev + (val - u_prev) * (val - u[col])\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def _mean_variance_finalize(\n",
    "    n_samples: int, n_a: npt.NDArray[np.int32], u_a: npt.NDArray[np.float64], M2_a: npt.NDArray[np.float64]\n",
    "):\n",
    "    \"\"\"\n",
    "    Finalize incremental values, acconting for missing elements (due to sparse input).\n",
    "    Non-sparse and sparse combined using Chan's parallel adaptation of Welford's.\n",
    "    The code assumes the sparse elements are all zero and ignores those terms.\n",
    "    \"\"\"\n",
    "    n_b = n_samples - n_a\n",
    "    delta = -u_a  # assumes u_b == 0\n",
    "    u = (n_a * u_a) / n_samples\n",
    "    M2 = M2_a + delta**2 * n_a * n_b / n_samples  # assumes M2_b == 0\n",
    "    return u, M2\n",
    "\n",
    "\n",
    "with mouse.axis_query(\n",
    "    measurement_name=\"RNA\",\n",
    "    obs_query=soma.experiment_query.AxisQuery(value_filter=\"tissue=='brain' and sex=='male'\"),\n",
    ") as query:\n",
    "    var_df = query.var().concat().to_pandas().set_index(\"soma_joinid\")\n",
    "    n_vars = len(var_df)\n",
    "\n",
    "    indexer = query._indexer\n",
    "    mvn = OnlineMatrixMeanVariance(query.n_obs, n_vars)\n",
    "    for arrow_tbl in query.X(\"raw\").tables():\n",
    "        var_dim = indexer.by_var(arrow_tbl[\"soma_dim_1\"])\n",
    "        data = arrow_tbl[\"soma_data\"].to_numpy()\n",
    "        mvn.update(var_dim, data)\n",
    "\n",
    "    u, v = mvn.finalize()\n",
    "\n",
    "var_df = var_df.assign(raw_mean=pd.Series(data=u, index=var_df.index))\n",
    "var_df = var_df.assign(raw_variance=pd.Series(data=v, index=var_df.index))\n",
    "\n",
    "display(var_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more complex example - counting cells per feature, grouped by dataset_id\n",
    "\n",
    "This example demonstrates a more complex example where the goal is to count the number of cells per gene, grouped by cell dataset_id.  The result is a Pandas DataFrame indexed by `obs.dataset_id` and `var.feature_id`, containing the number of cells per pair.\n",
    "\n",
    "This example does not use positional indexing, but rather demonstrates the use of Pandas DataFrame `join` to join on the `soma_joinid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mouse.axis_query(\n",
    "    measurement_name=\"RNA\",\n",
    "    obs_query=somacore.AxisQuery(value_filter=\"tissue=='brain'\"),\n",
    ") as query:\n",
    "    obs_df = query.obs(column_names=[\"soma_joinid\", \"dataset_id\"]).concat().to_pandas().set_index(\"soma_joinid\")\n",
    "    var_df = query.var().concat().to_pandas().set_index(\"soma_joinid\")\n",
    "    n_cells_by_dataset = pd.Series(\n",
    "        0,\n",
    "        index=pd.MultiIndex.from_product(\n",
    "            (var_df.index, obs_df.dataset_id.unique()), names=[\"soma_joinid\", \"dataset_id\"]\n",
    "        ),\n",
    "        dtype=np.int64,\n",
    "        name=\"n_cells\",\n",
    "    )\n",
    "\n",
    "    for X_tbl in query.X(\"raw\").tables():\n",
    "        # Group by dataset_id and count unique (genes, dataset_id)\n",
    "        value_counts = (\n",
    "            soma.experiment_query.X_as_series(X_tbl)\n",
    "            .to_frame()\n",
    "            .join(obs_df[[\"dataset_id\"]], on=\"soma_dim_0\")\n",
    "            .reset_index(level=1)\n",
    "            .drop(columns=[\"soma_data\"])\n",
    "            .value_counts()\n",
    "        )\n",
    "        np.add.at(n_cells_by_dataset, n_cells_by_dataset.index.get_indexer(value_counts.index), value_counts.to_numpy())\n",
    "\n",
    "# drop any combinations that are not observed\n",
    "n_cells_by_dataset = n_cells_by_dataset[n_cells_by_dataset > 0]\n",
    "\n",
    "# and join with var_df to pick up feature_id and feature_name\n",
    "n_cells_by_dataset = (\n",
    "    n_cells_by_dataset.to_frame()\n",
    "    .reset_index(level=1)\n",
    "    .join(var_df[[\"feature_id\", \"feature_name\"]])\n",
    "    .set_index([\"dataset_id\", \"feature_id\"])\n",
    ")\n",
    "\n",
    "display(n_cells_by_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3da8ec1c162cd849e59e6ea2824b2e353dce799884e910aae99411be5277f953"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
